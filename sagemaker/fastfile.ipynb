{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you are going to use Sagemaker in a local environment, you need access to an IAM Role with the required permissions for Sagemaker. You can find more about it [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that SageMaker by default uses the latest [AWS Deep Learning Container (DLC)](https://aws.amazon.com/machine-learning/containers/), but if you want to use your own DLC, you can set the `use_ecr_image` flag to `True` and set the `ecr_image` variable. Also note that if using FSx when launching the SageMaker notebook instance, you will need to use the same `subnet` and `security_group_config`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_ecr_image = False\n",
    "use_fsx = False\n",
    "kwargs = {}\n",
    "\n",
    "if use_ecr_image:\n",
    "    ecr_image = \"<ECR_IMAGE_URI>\"\n",
    "    kwargs[\"image_uri\"] = ecr_image\n",
    "\n",
    "if use_fsx:\n",
    "    subnet_config = [\"<SUBNET_CONFIG_ID>\"]\n",
    "    security_group_config = [\"<SECURITY_GROUP_CONFIG>\"]\n",
    "    kwargs[\"subnets\"] = subnet_config\n",
    "    kwargs[\"security_group_ids\"] = security_group_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Training Job\n",
    "\n",
    "We will now set the hyperparameters and define the estimator object for our training job.  Since we are using DeepSpeed, we must provide a DeepSpeed config JSON file, which is located in the `code/` folder. \n",
    "\n",
    " We will  use the `PyTorch` estimator class and configure it to use the `torch_distributed` distribution, which will launch a the training job using `torchrun`.  This is a popular launcher for PyTorch-based distributed training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    # \"gradient_checkpointing\": True,\n",
    "    # \"batch_size\": 64,\n",
    "    # \"epochs\": 2,\n",
    "    # \"max_steps\": 50,\n",
    "    # \"deepspeed_config\": \"/opt/ml/code/deepspeed_config.json\",\n",
    "}\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"start.py\",\n",
    "    framework_version=\"2.3.0\",\n",
    "    py_version=\"py311\",\n",
    "    source_dir=\"./code\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    # distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}},\n",
    "    role=role,\n",
    "    instance_count=1,  # default: 2\n",
    "    instance_type=\"ml.p4d.24xlarge\",  # default: ml.g5.12xlarge\n",
    "    keep_alive_period_in_seconds=600,\n",
    "    volume_size=500,  # EBS 卷大小，单位为 GB\n",
    "    # max_run=1800,\n",
    "    input_mode='FastFile',  # Available options: File | Pipe | FastFile\n",
    "    base_job_name=\"pytorch-training-fastfile\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    debugger_hook_config=False,\n",
    "    disable_output_compression=True,\n",
    "    **kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the traning job \n",
    "We can now start our training job, with the `.fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "estimator.fit({'surface': 's3://datalab/goldwind/surface/', 'upper': 's3://datalab/goldwind/upper/', 'pretrained_model': 's3://datalab/goldwind/pretrained_model/', 'aux_data': 's3://datalab/goldwind/aux_data/'}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate the warm pool cluster if no longer needed\n",
    "\n",
    "Once finished experimenting, you can terminate the warm pool cluster to reduce billed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.update_training_job(\n",
    "    estimator.latest_training_job.job_name, resource_config={\"KeepAlivePeriodInSeconds\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
